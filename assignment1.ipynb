{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69WPLPGqOKxv",
        "outputId": "8d72f7ad-cdca-4968-81de-f3a048bfb8ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np \n",
        "from numpy import cos, sin\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing\n",
        "import time\n",
        "# import visualisation\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as td\n",
        "import torch.optim as optim\n",
        "torch.backends.cudnn.benchmark = True \n",
        "\n",
        "import torchvision as tv\n",
        "\n",
        "\n",
        "print(\"Using torch\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfDDfDrvOKx2",
        "outputId": "3a68cb74-5003-41b9-db81-e816e0ad3406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda:0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Fetching the device that will be used throughout this notebook\n",
        "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
        "print(\"Using device\", device)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATASET_PATH = \"drive/MyDrive/Liverpool/Assignments/Year 3/COMP341/COMP341 - Assignment 01 - Data/Data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "9yRDLP48OKx3"
      },
      "outputs": [],
      "source": [
        "colors = [[31, 120, 180], [51, 160, 44]]\n",
        "colors = [(r / 255, g / 255, b / 255) for (r, g, b) in colors]\n",
        "\n",
        "def plot_epochs(train_history, val_history, plotType=\"loss\"):\n",
        "    x = np.arange(1, len(train_history) + 1)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(x, val_history, color=colors[1], label=f\"Validation {plotType}\", linewidth=2)\n",
        "    plt.plot(x, train_history, color=colors[0], label=f\"Training {plotType}\", linewidth=2)\n",
        "    plt.ylabel(f'{plotType}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title(f\"Evolution of the training and validation {plotType}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "JD85qwRvOKx4"
      },
      "outputs": [],
      "source": [
        "def get_cnn_output_size(in_size, kernel_size, stride=1, padding=0):\n",
        "    integer = int((in_size - kernel_size + 2 * padding) / stride) == ((in_size - kernel_size + 2 * padding) / stride)\n",
        "    if not integer:\n",
        "        print(\"not int\", ((in_size - kernel_size + 2 * padding) / stride))\n",
        "    return int((in_size - kernel_size + 2 * padding) / stride) + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class GraspDataset(Dataset):\n",
        "\n",
        "  def __init__(self, root_dir, transforms=None):\n",
        "      self.root_dir = root_dir\n",
        "      self.transforms = transforms\n",
        "\n",
        "      # List of all scenes for all objects in the dataset\n",
        "      self.scene_paths = []\n",
        "      for object_name in os.listdir(root_dir):\n",
        "        for scene_index in range(5): # Scene index ranges from 0 to 4 for all objects\n",
        "\n",
        "          scene_root = f\"{root_dir}/{object_name}/{scene_index}_{object_name}_\"\n",
        "\n",
        "          # Make sure a scene with this index exists for this object\n",
        "          grasp_path = scene_root + \"grasps.txt\"\n",
        "          if not os.path.exists(grasp_path): continue\n",
        "\n",
        "          # Add scene files and appened to the list\n",
        "          scene = {\n",
        "              \"grasps\": grasp_path,\n",
        "              \"rgb\": scene_root + \"RGB.png\",\n",
        "              \"mask\": scene_root + \"mask.png\",\n",
        "              \"pDepth\": scene_root + \"perfect_depth.tiff\",\n",
        "              \"sDepth\": scene_root + \"stereo_depth.tiff\"\n",
        "          }\n",
        "          self.scene_paths.append(scene)\n",
        "\n",
        "  # This must return the length of the dataset\n",
        "  def __len__(self):\n",
        "    return len(self.scene_paths)\n",
        "\n",
        "  # This must return the single dataset item at index idx\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    # Load the grasps\n",
        "    grasps = []\n",
        "    with open(self.scene_paths[idx][\"grasps\"]) as file:\n",
        "      lines = file.readlines()\n",
        "      for line in lines:\n",
        "        x, y, theta, openning, jaw_size = [float(number) for number in line.split(\";\")]\n",
        "        grasp = [x, y, theta, openning, jaw_size]\n",
        "        grasps.append(grasp)\n",
        "    grasps = np.array(grasps)\n",
        "\n",
        "    # Load the RGB image\n",
        "    image = Image.open(self.scene_paths[idx][\"rgb\"])\n",
        "    image_resized = tv.transforms.Resize((1047, 1047))(image)\n",
        "    rgb = np.array(image_resized, dtype=float) / 255\n",
        "\n",
        "    rgb_reshaped = np.zeros([3, rgb.shape[0], rgb.shape[1]])\n",
        "    rgb_reshaped[0,:,:] = rgb[:,:,0]\n",
        "    rgb_reshaped[1,:,:] = rgb[:,:,1]\n",
        "    rgb_reshaped[2,:,:] = rgb[:,:,2]\n",
        "\n",
        "    if self.transforms: \n",
        "      rgb_reshaped = self.transforms(rgb_reshaped)\n",
        "\n",
        "    return (rgb_reshaped, grasps[0])"
      ],
      "metadata": {
        "id": "HPGyY2z4RiWt"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show off the dataset\n",
        "index = 3\n",
        "dataset = GraspDataset(DATASET_PATH + \"/training\")\n",
        "loader = td.DataLoader(dataset, batch_size=4, shuffle=False, drop_last=False, num_workers=2)\n",
        "\n",
        "batch = next(iter(loader))\n",
        "image_array = np.uint8(np.array(batch[0][index]) * 255)\n",
        "\n",
        "print(\"grasp:\", batch[1][index])\n",
        "display(Image.fromarray(image_array))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "UMna7vFPf8v7",
        "outputId": "50255da9-aacb-4457-8c1e-aa7f8cf02cbd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grasp: tensor([512.5854, 494.2139, -64.5562, 163.5000,  25.6021], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2713\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2714\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 1024), '|u1')",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-d54da1932d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grasp:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2714\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2716\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot handle this data type: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtypekey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2717\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2718\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 1024), |u1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNSAt2C3OKx5",
        "outputId": "fba693b0-0153-43fc-bceb-9d92de33a06c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():  # GPU operation have separate seed\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "\n",
        "num_workers = multiprocessing.cpu_count()\n",
        "\n",
        "def gen_transforms(resize=None, imgs_mean=(0.5,), imgs_std=(0.5,)):\n",
        "    tst_trans = [tv.transforms.ToTensor()]\n",
        "    if resize is not None:\n",
        "        tst_trans.append(tv.transforms.Resize(resize[0]))\n",
        "        tst_trans.append(tv.transforms.CenterCrop(resize[1]))\n",
        "    tst_trans.append(tv.transforms.Normalize(mean=imgs_mean, std=imgs_std))\n",
        "    return tv.transforms.Compose(tst_trans)\n",
        "\n",
        "def get_train_test_data(image_resize=None):\n",
        "    transforms = gen_transforms(image_resize)\n",
        "    trainData = GraspDataset(\n",
        "        root_dir=f'{DATASET_PATH}/training',\n",
        "        transforms=None)\n",
        "    # a = ({\n",
        "    #     loader: Callable[[str], Any],\n",
        "    #     target_transform: Optional[Callable] = None,\n",
        "    #     is_valid_file: Optional[Callable[[str], bool]] = None,\n",
        "    # })\n",
        "    return trainData\n",
        "\n",
        "\n",
        "def get_train_loader(batchSize, resize=None):\n",
        "    trainData = get_train_test_data(resize)\n",
        "    trainLoader = td.DataLoader(trainData, batch_size=batchSize, shuffle=True, drop_last=False, num_workers=4)\n",
        "    return trainLoader\n",
        "\n",
        "trainLoader = get_train_loader(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "4SzI9dlCOKx6"
      },
      "outputs": [],
      "source": [
        "def getLoss():\n",
        "    return nn.MSELoss()\n",
        "\n",
        "def getOptimiser(model, learningRate):\n",
        "    #optimiser = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    optimiser = optim.Adam(model.parameters(), lr=learningRate)\n",
        "    return optimiser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "m2KPusVhOKx6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(model, batch_size, n_epochs, learning_rate, resize=None):\n",
        "    print(f\"batch size: {batch_size}\")\n",
        "    print(f\"n epochs: {n_epochs}\")\n",
        "    print(f\"learning rate: {learning_rate}\")\n",
        "    print(\"=\"*20)\n",
        "    \n",
        "    trainLoader = get_train_loader(batch_size, resize)\n",
        "    lossFn = getLoss()\n",
        "    optimizer = getOptimiser(model, learning_rate)\n",
        "\n",
        "    train_history = []\n",
        "    training_start_time = time.time()\n",
        "    \n",
        "    model = model.to(device) # Move model to gpu\n",
        "    model.train() # Set the model to training mode (for DropOut)\n",
        "\n",
        "    for epoch in range(n_epochs):  # loop over the dataset for n_epoch\n",
        "        epoch_loss = 0\n",
        "        \n",
        "        with tqdm(trainLoader, unit=\"batch\") as tepoch:\n",
        "            for rgb, grasp in tepoch:   #for each batch\n",
        "                tepoch.set_description(f\"Epoch {epoch}\")\n",
        "                # Move tensors to gpu\n",
        "                rgb = torch.FloatTensor(rgb.numpy())\n",
        "                rgb, grasp = rgb.to(device), grasp.to(device)\n",
        "               \n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward + backward + optimize\n",
        "                outputs = model(rgb)\n",
        "                # _, predicted = outputs.argmax(dim=1, keepdim=True).squeeze()\n",
        "                #  = torch.max(outputs, 1)\n",
        "                # print('out', outputs.size(), 'targets', grasps.size())\n",
        "                loss = lossFn(outputs, grasp)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                # add to running totals\n",
        "                epoch_loss += loss.item()\n",
        "        epoch_loss = epoch_loss / len(trainLoader)\n",
        "        # print(f\"Epoch #{epoch + 1} train_loss: {round(epoch_loss,2)} accuracy: {round(epoch_accuracy,1)}% took: {round(time.time() - start_time,2)}s\") \n",
        "        train_history.append(epoch_loss)\n",
        "\n",
        "    print(f\"Training Finished, took {round(time.time() - training_start_time,1)}s\")\n",
        "    return train_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "RcKas80MOKx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d059eec-a995-4e6e-c7a2-657ed343f60c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "257"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "get_cnn_output_size(259, kernel_size=3, stride=1, padding=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "-AJhum8iOKx8"
      },
      "outputs": [],
      "source": [
        "class DeepConvNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepConvNN, self).__init__()\n",
        "        #in = 1047 x 1047\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=0), #out = 523x523\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            # nn.Dropout(0.3),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0), #out = 521x521\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            # nn.Dropout(0.3),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0), #out = 519x519\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0) #out = 259x259                 \n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1), #out = 259x259\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            # nn.Dropout(0.3),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=0), #out = 129x129\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), #out = 129x129\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            # nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "            # MaxPool could be used instead of stride 2\n",
        "        )\n",
        "\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0), #out = 127x127\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            # nn.Dropout(0.3),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0), #out = 63x63\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            # nn.Dropout(0.3),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0),  #out = 61x61\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128)\n",
        "        )\n",
        "\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0), #out = 59x59\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            # nn.Dropout(0.3),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=0), #out = 29x29\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            # nn.Dropout(0.3),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=0), #out = 14x14\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256)\n",
        "        )\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        # self.pool = nn.AdaptiveAvgPool2d((4,4))\n",
        "        self.flattened_size = 256 * 7 * 7 #36864\n",
        "\n",
        "        self.regressionBlock = nn.Sequential(\n",
        "            # nn.Dropout(0.5),\n",
        "            nn.Linear(self.flattened_size, 512),\n",
        "            nn.Linear(512, 5),\n",
        "            # nn.Dropout(0.5), \n",
        "            # nn.Linear(2048, 5)  # We also found two fully connected layers to reduce accuracy\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, self.flattened_size)\n",
        "        x = self.regressionBlock(x)\n",
        "        print(x.size())\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "2TTKm5biOKx9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762,
          "referenced_widgets": [
            "28f862711238434498db8c044c9f799d",
            "01496e68152e458c8c122003c36ecad9",
            "49c86e80cfbd4fbc8f9c9168a2c6a6b1",
            "e6d4136c9a0e4e1cb6651eaa8796d434",
            "4f4cee546b184be1a648eb2876e7338f",
            "a237c0ded2fa4f4fa60c597f42f1c60e",
            "bbc264fed9a94d9496398db4a99ca9f2",
            "a820294f530c4bf1aaede06460285ecf",
            "932c936e530847aa9d422cba03d11fda",
            "212ca770f17c43f7b838bd159de1cd53",
            "1ed574905dc24f02b1802a6b61fd9db2"
          ]
        },
        "outputId": "750dceb5-4797-4ae6-bd64-0d42332c10bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch size: 4\n",
            "n epochs: 5\n",
            "learning rate: 0.01\n",
            "====================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28f862711238434498db8c044c9f799d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 5])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-e0aa52ac7c85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepConvNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrains_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-66-c1b3085a6554>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, batch_size, n_epochs, learning_rate, resize)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;31m# print('out', outputs.size(), 'targets', grasps.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrasp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;31m# add to running totals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Double but expected Float"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 4\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 0.01\n",
        "resize = (1047, 1047)\n",
        "\n",
        "nnet = DeepConvNN()\n",
        "\n",
        "trains_loss = train(nnet, BATCH_SIZE, EPOCHS, LEARNING_RATE, resize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJI6erJmOKx-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTSpqxdyOKx-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "538ENw3LOKx-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "28f862711238434498db8c044c9f799d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01496e68152e458c8c122003c36ecad9",
              "IPY_MODEL_49c86e80cfbd4fbc8f9c9168a2c6a6b1",
              "IPY_MODEL_e6d4136c9a0e4e1cb6651eaa8796d434"
            ],
            "layout": "IPY_MODEL_4f4cee546b184be1a648eb2876e7338f"
          }
        },
        "01496e68152e458c8c122003c36ecad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a237c0ded2fa4f4fa60c597f42f1c60e",
            "placeholder": "​",
            "style": "IPY_MODEL_bbc264fed9a94d9496398db4a99ca9f2",
            "value": "Epoch 0:   0%"
          }
        },
        "49c86e80cfbd4fbc8f9c9168a2c6a6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a820294f530c4bf1aaede06460285ecf",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_932c936e530847aa9d422cba03d11fda",
            "value": 0
          }
        },
        "e6d4136c9a0e4e1cb6651eaa8796d434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_212ca770f17c43f7b838bd159de1cd53",
            "placeholder": "​",
            "style": "IPY_MODEL_1ed574905dc24f02b1802a6b61fd9db2",
            "value": " 0/8 [00:02&lt;?, ?batch/s]"
          }
        },
        "4f4cee546b184be1a648eb2876e7338f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a237c0ded2fa4f4fa60c597f42f1c60e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbc264fed9a94d9496398db4a99ca9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a820294f530c4bf1aaede06460285ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "932c936e530847aa9d422cba03d11fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "212ca770f17c43f7b838bd159de1cd53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ed574905dc24f02b1802a6b61fd9db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}