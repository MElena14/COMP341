{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MElena14/COMP341/blob/main/assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfd5JgWoICcg"
      },
      "source": [
        "#### imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k3dxF3QaJqeD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/users/sgmsempl/.conda/envs/torch/lib/python3.9/site-packages/ale_py/roms/__init__.py:89: DeprecationWarning: Automatic importing of atari-py roms won't be supported in future releases of ale-py. Please migrate over to using `ale-import-roms` OR an ALE-supported ROM package. To make this warning disappear you can run `ale-import-roms --import-from-pkg atari_py.atari_roms`.For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management\n",
            "  ROMS = resolve_roms()\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import math\n",
        "from collections import deque, namedtuple\n",
        "import cv2\n",
        "import pickle\n",
        "from tqdm.notebook import tqdm\n",
        "import PIL\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import gym"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyBEYPP0H-qS"
      },
      "source": [
        "#### Render OpenAI Gym Environments from CoLab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "AL2uvFBoH4ji",
        "outputId": "4238a76d-4f8d-48ff-c34b-b1af70f9ff7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "not in colab\n",
            "Using device cuda:1\n"
          ]
        }
      ],
      "source": [
        "# HIDE OUTPUT\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
        "    env_name = \"Atlantis-v0\"\n",
        "    !wget http://www.atarimania.com/roms/Roms.rar \n",
        "    !unrar x -o+ /content/Roms.rar >/dev/nul\n",
        "    !python -m atari_py.import_roms /content/ROMS >/dev/nul\n",
        "\n",
        "    !pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "    !apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "\n",
        "    !apt-get update > /dev/null 2>&1\n",
        "    !apt-get install cmake > /dev/null 2>&1\n",
        "    !pip install --upgrade setuptools 2>&1\n",
        "    !pip install ez_setup > /dev/null 2>&1\n",
        "    !pip install gym[atari] > /dev/null 2>&1\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    env_name = \"ALE/Atlantis-v5\"\n",
        "    print('not in colab')\n",
        "    device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:1\")\n",
        "print(\"Using device\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjkT6v3pHnVv",
        "outputId": "5927ff8d-d5de-46f3-f192-70708746f48f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action Space: Discrete(4)\n",
            "possible actions: ['NOOP', 'FIRE', 'RIGHTFIRE', 'LEFTFIRE']\n",
            "Observation Space: Box(0, 255, (210, 160, 3), uint8)\n",
            "Max Episode Steps: 27000\n",
            "Nondeterministic: False\n",
            "Reward Range: (-inf, inf)\n",
            "Reward Threshold: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
            "[Powered by Stella]\n"
          ]
        }
      ],
      "source": [
        "def query_environment(name):\n",
        "  env = gym.make(name)\n",
        "  spec = gym.spec(name)\n",
        "  print(f\"Action Space: {env.action_space}\")\n",
        "  print(f\"possible actions: {env.unwrapped.get_action_meanings()}\")\n",
        "  print(f\"Observation Space: {env.observation_space}\")\n",
        "  print(f\"Max Episode Steps: {spec.max_episode_steps}\")\n",
        "  print(f\"Nondeterministic: {spec.nondeterministic}\")\n",
        "  print(f\"Reward Range: {env.reward_range}\")\n",
        "  print(f\"Reward Threshold: {spec.reward_threshold}\")\n",
        "  \n",
        "query_environment(\"Atlantis-v0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8X-yeVrRHpTf"
      },
      "outputs": [],
      "source": [
        "\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "# display = Display(visible=0, size=(1400, 900))\n",
        "# display.start()\n",
        "\n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment \n",
        "and displaying it.\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  print(mp4list[-1])\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[-1]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "if IN_COLAB:\n",
        "    from gym.wrappers import Monitor\n",
        "    def wrap_env(env, record_every=1, folder='./video'):\n",
        "        env = Monitor(env, folder, force=True)\n",
        "        return env\n",
        "else:\n",
        "    from gym.wrappers.record_video import RecordVideo\n",
        "    def wrap_env(env, record_every=1, folder='./video'):\n",
        "        env = RecordVideo(env, folder, episode_trigger=lambda i: i % record_every == 0)\n",
        "        return env\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvpErA1hITFs"
      },
      "source": [
        "#### inital random agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AVzkJJHendfi"
      },
      "outputs": [],
      "source": [
        "def show_random_agent():\n",
        "  env = wrap_env(gym.make(env_name))\n",
        "\n",
        "  observation = env.reset()\n",
        "  score = 0\n",
        "  while True:\n",
        "      env.render()\n",
        "      action = env.action_space.sample()\n",
        "      observation, reward, done, info = env.step(action)\n",
        "      score += reward\n",
        "      if done:\n",
        "        print(f\"finished! random agent's score is {score}\")\n",
        "        break\n",
        "  env.close()\n",
        "  show_video()\n",
        "show_random_agent()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkV2DFe4JwC9"
      },
      "source": [
        "#### Deep QN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Mx-ZVJ4s4nV_"
      },
      "outputs": [],
      "source": [
        "class DQNCnn(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "        \n",
        "        self.features = nn.Sequential( # in = 84x84\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        ) # out = 7x7\n",
        "        self.feature_size = 7 * 7 * 64\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.feature_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.num_actions)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg5IwV9Gndfl"
      },
      "source": [
        "#### ResNetDQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krpJGCQ-ndfl"
      },
      "source": [
        "##### ResNetBlock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SsP2JnGWndfm"
      },
      "outputs": [],
      "source": [
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, depth_in, activation_func, depth_out=-1):\n",
        "        super().__init__()\n",
        "        self.downSampleResidul = True\n",
        "        if depth_out == -1:\n",
        "            depth_out = depth_in\n",
        "            self.downSampleResidul = False\n",
        "\n",
        "        self.resBlock = nn.Sequential(\n",
        "            nn.BatchNorm2d(depth_in),\n",
        "            activation_func(inplace=True),\n",
        "            nn.Conv2d(depth_in, depth_out, kernel_size=3, padding=1, stride=1 if not self.downSampleResidul else 2, bias=False),\n",
        "            nn.BatchNorm2d(depth_out),\n",
        "            activation_func(inplace=True),\n",
        "            nn.Conv2d(depth_out, depth_out, kernel_size=3, padding=1, bias=False)\n",
        "        )\n",
        "\n",
        "        self.downsampleRes = nn.Sequential(\n",
        "            nn.BatchNorm2d(depth_in),\n",
        "            activation_func(inplace=True),\n",
        "            nn.Conv2d(depth_in, depth_out, kernel_size=1, stride=2, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.resBlock(x)\n",
        "        if self.downSampleResidul:\n",
        "            x = self.downsampleRes(x)\n",
        "        return z + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPg5kxuundfn",
        "outputId": "2edfdf27-7973-4d6c-8645-fc33d9cf2687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "not int 9.5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_cnn_output_size(in_size, kernel_size, stride=1, padding=0):\n",
        "    integer = int((in_size - kernel_size + 2 * padding) / stride) == ((in_size - kernel_size + 2 * padding) / stride)\n",
        "    if not integer:\n",
        "        print(\"not int\", ((in_size - kernel_size + 2 * padding) / stride))\n",
        "    return int((in_size - kernel_size + 2 * padding) / stride) + 1\n",
        "get_cnn_output_size(in_size=20, kernel_size=3, stride=2, padding=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTcVbQMrndfo"
      },
      "source": [
        "##### ResNetDQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9zx6rGfDndfp"
      },
      "outputs": [],
      "source": [
        "class ResNetDQN(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "        super(ResNetDQN, self).__init__()\n",
        "        #in = 159x159\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 16, kernel_size=3, stride=2, padding=0), #out = 79x79\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0), #out = 77x77\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0), #out = 75x75\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=0) #out = 37x37\n",
        "        )\n",
        "        \n",
        "        self.featureExtractionBlock = nn.Sequential(\n",
        "            ResNetBlock(32, nn.SiLU, 64),  #out = 19x19\n",
        "            ResNetBlock(64, nn.SiLU),      #out = 19x19\n",
        "            ResNetBlock(64, nn.SiLU),      #out = 19x19 \n",
        "            ResNetBlock(64, nn.SiLU, 128), #out = 10x10\n",
        "            ResNetBlock(128, nn.SiLU),     #out = 10x10\n",
        "        )\n",
        "        # self.pool = nn.AdaptiveAvgPool2d((4,4))\n",
        "        self.flattened_size = 128 * 10 * 10\n",
        "        self.regressionBlock = nn.Sequential(\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(self.flattened_size, 1024),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.Linear(1024, self.num_actions),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.featureExtractionBlock(x)\n",
        "        # x = self.pool(x)\n",
        "        x = x.view(-1, self.flattened_size)\n",
        "        x = self.regressionBlock(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSFkzLbg0p7q"
      },
      "source": [
        "#### utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "uS4Ms1_30tbT",
        "outputId": "3dd6f4ca-7ad1-4481-d2b0-0a4f33a5262c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJ8AAACfCAAAAADCcFQ8AAACcUlEQVR4nO3aT0iTcRzH8bfbUDfRMVGT/NMs05aCmoekblaX8ixdxIPQsUPRLbp171DQpUOHiFAkpFt/LIpSEMppChqkFeH8Szp9Zs9mHcLaM4N6wMfH4vM6PfDdnr35Pfv7YyAiIiIiIiIi8m/LcjuAkgboTwJFTQDRmGXqcyMpXfbeJhie34Bgcz7EP8b+fJ+d1HYJuB0GqOjp6a7OGLu9focTDwqOPrxZa8T21QUmeTSTMXe7rzI1HTnybrDLCNQ2E59+sZ4xd7tvT6ruAo1d+1sBEle3zN3uy0l6A5CVGwDwbp273beWWoqWvU+ujK8GizAPTKUy5m6//7VuPC1pv07HwGTTCeCGkTF3u89fHRjKW257EzOz/QUnWX6yZJ27fX2NudIwxbOLJl99wXVyKs24Ze52HzPeY3DfBIIRE2oWrH1uX1/AAxubB5uHIiIiIiK7kr3vz8Ue4qsARV7AXHSiyMre74/OAh4/A+gIAdO3nCiysrN+nsu9azSk+oCKrjAjdz87VZX2mH9/U1+VOWXMLgRKocqXNOcmdiDPzvqFOq9xdni8PtLNReDVS8ei0th4/mXXcaX8eJ9xqoUQ3HvtXFQaG32efMoLCaYKCwHMzJ0SZ9joy/KT48fn9QO/3Qtzgo0+4znn2kdGI3d6OQ/1KwPOVf1i4/WR25h4WxPzlRljtFCd/2n4g3NZP9l4f0kMHvJPfCn1jsHA0NxqKLwTe0v2Pt/OBBgdBzidB8z3O1FkZW8Nol5+7B9GfUDCgR4RERERERERERERERERERERERERERH5L9QcdOCk2/gf8PVv23cuEREREZFd6TtN75mgCxyKwQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=159x159 at 0x7FD0C9EC6F10>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# taken from https://github.com/deepanshut041/Reinforcement-Learning/blob/master/algos/preprocessing/stack_frame.py\n",
        "def preprocess_frame(screen, exclude, output):\n",
        "    \"\"\"Preprocess Image.\n",
        "        \n",
        "        Params\n",
        "        ======\n",
        "            screen (array): RGB Image\n",
        "            exclude (tuple): Section to be croped (UP, RIGHT, DOWN, LEFT)\n",
        "            output (int): Size of output image\n",
        "        \"\"\"\n",
        "    # TConver image to gray scale\n",
        "    screen = cv2.cvtColor(screen, cv2.COLOR_RGB2GRAY)\n",
        "    \n",
        "    #Crop screen[Up: Down, Left: right] \n",
        "    screen = screen[exclude[0]:exclude[2], exclude[3]:exclude[1]]\n",
        "    \n",
        "    # Convert to float, and normalized\n",
        "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
        "    \n",
        "    # Resize image to 84 * 84\n",
        "    screen = cv2.resize(screen, (output, output), interpolation = cv2.INTER_AREA)\n",
        "    return screen\n",
        "\n",
        "def stack_frame(stacked_frames, frame, is_new):\n",
        "    \"\"\"Stacking Frames.\n",
        "        \n",
        "        Params\n",
        "        ======\n",
        "            stacked_frames (array): Four Channel Stacked Frame\n",
        "            frame: Preprocessed Frame to be added\n",
        "            is_new: Is the state First\n",
        "        \"\"\"\n",
        "    if is_new:\n",
        "        stacked_frames = np.stack(arrays=[frame, frame, frame, frame])\n",
        "        stacked_frames = stacked_frames\n",
        "    else:\n",
        "        stacked_frames[0] = stacked_frames[1]\n",
        "        stacked_frames[1] = stacked_frames[2]\n",
        "        stacked_frames[2] = stacked_frames[3]\n",
        "        stacked_frames[3] = frame\n",
        "    \n",
        "    return stacked_frames\n",
        "\n",
        "frame_crops = {'DQNcnn': 84, 'ResNetDQN': 159}\n",
        "\n",
        "def get_stack_frames(net='DQNcnn'):\n",
        "    size = frame_crops[net]\n",
        "    def stack_frames(frames, state, is_new=False):\n",
        "        frame = preprocess_frame(state, (0, -10, -100, 9), size)\n",
        "        frames = stack_frame(frames, frame, is_new)\n",
        "        return frames\n",
        "    return stack_frames\n",
        "\n",
        "def show_cropped_image():\n",
        "    env = gym.make(env_name)\n",
        "    observation = env.reset()\n",
        "    t, done = 0, False\n",
        "    while not done and t < 260:\n",
        "      # env.render()\n",
        "      action = env.action_space.sample() \n",
        "      observation, reward, done, info = env.step(action)\n",
        "      \n",
        "      t += 1\n",
        "                                # (UP, RIGHT, DOWN, LEFT)\n",
        "    f = preprocess_frame(observation, (0, -10, -100, 9), 159)\n",
        "    return PIL.Image.fromarray(np.uint8(f * 255), mode=\"L\")\n",
        "show_cropped_image()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gQK4tV3qndfu"
      },
      "outputs": [],
      "source": [
        "def plot_epsilon_func(eps_func, n_episodes=1000):\n",
        "    episodes = range(n_episodes)\n",
        "    eps = [eps_func(i) for i in episodes]\n",
        "    plt.plot(episodes, eps)\n",
        "    plt.show()\n",
        "\n",
        "def iqr_mean(scores):\n",
        "    scores = np.array(scores)\n",
        "    q25, q75 = np.percentile(scores, [25, 75])\n",
        "    meaners = scores[np.logical_and(scores > q25, scores < q75)]\n",
        "    return q25, q75, meaners.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtzA_Zt7tTOs"
      },
      "source": [
        "### memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "W14ncSaOKCVj"
      },
      "outputs": [],
      "source": [
        "# Experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "from numpy.typing import NDArray\n",
        "class ReplayMemory:\n",
        "    def __init__(self, buffer_size, batch_size, device, filename=None, top=1):\n",
        "        self.memory = deque(maxlen=buffer_size) if filename is None else pickle.load(open(filename, 'rb'))\n",
        "        self.batch_size = int(batch_size/top) if top < 1 else batch_size\n",
        "        self.top = top\n",
        "        self.device = device\n",
        "        self.mean = lambda l: sum(l)/len(l)\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        Experience = (state, action, reward, next_state, float(done))\n",
        "        self.memory.append(Experience)\n",
        "    def _as_tensor(self, np_array:NDArray, dtype=torch.float):\n",
        "        tensor = torch.from_numpy(np.array(np_array))\n",
        "        return tensor.type(dtype, non_blocking=True).to(self.device, non_blocking=True)\n",
        "    def sample(self):\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "        if self.top < 1:\n",
        "            experiences.sort(key=lambda e:e[2])\n",
        "            experiences = experiences[int((self.top*self.batch_size)-1):int(self.batch_size-1)]\n",
        "        states, actions, rewards, next_states, dones = zip(*experiences)\n",
        "        states, next_states = self._as_tensor(states), self._as_tensor(next_states)\n",
        "        actions, rewards, dones = self._as_tensor(actions, dtype=torch.int64), self._as_tensor(rewards), self._as_tensor(dones, dtype=torch.uint8)\n",
        "        return (states, actions, rewards, next_states, dones)\n",
        "        \n",
        "\n",
        "    def save(self, filename):\n",
        "        pickle.dump(self.memory, open(filename, 'wb') )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YLCgDIQ1RfH"
      },
      "source": [
        "### Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_SOXNZ20yFQ4"
      },
      "outputs": [],
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, args):\n",
        "        \"\"\"\n",
        "        args = {\n",
        "            input_shape:  (tuple) dimension of each state (C, H, W)\n",
        "            action_size (int): dimension of each action\n",
        "            seed (int): random seed\n",
        "            device(string): Use Gpu or CPU\n",
        "            buffer_size (int): replay buffer size\n",
        "            batch_size (int):  torch minibatch size\n",
        "            gamma (float): discount factor\n",
        "            lr (float): learning rate \n",
        "            update_every (int): how often to update the network\n",
        "            replay_after (int): After which replay to be started\n",
        "            model(Model): Pytorch Model\n",
        "            base_filename (str): base filename to save models to\n",
        "        }\n",
        "        \"\"\"\n",
        "        self.input_shape = args['input_shape']\n",
        "        self.action_size = args['action_size']\n",
        "        self.device = args['device']\n",
        "        self.buffer_size = args['buffer_size']\n",
        "        self.batch_size = args['batch_size']\n",
        "        self.gamma = args['gamma']\n",
        "        self.lr = args['lr']\n",
        "        self.learn_every = args['learn_every']\n",
        "        self.replay_after = args['replay_after']\n",
        "        self.network = args['model']\n",
        "        self.tau = args['tau']\n",
        "        self.base_filename = args['base_filename']\n",
        "        episodes = args['episodes'] if 'episodes' in args else 10000\n",
        "        \n",
        "        \n",
        "        # Q-Network\n",
        "        self.policy_net = self.network(self.input_shape, self.action_size).to(self.device)\n",
        "        self.target_net = self.network(self.input_shape, self.action_size).to(self.device)\n",
        "        self.optimizer = torch.optim.AdamW(self.policy_net.parameters(), lr=self.lr, )\n",
        "        self.loss = nn.SmoothL1Loss()\n",
        "        self.losses = torch.zeros(int(episodes/self.learn_every+2)).to(self.device)\n",
        "        self.nextLossIdx = torch.tensor([0],dtype=torch.uint8).to(self.device)\n",
        "\n",
        "        self.memoryTop = args['memory_top'] if 'memory_top' in args else False\n",
        "        self.memory = ReplayMemory(self.buffer_size, self.batch_size, self.device, top=self.memoryTop)\n",
        "        \n",
        "        self.time_step = 0\n",
        "\n",
        "    def save(self):\n",
        "        torch.save(self.policy_net.state_dict(), f\"{self.base_filename}.policy.net\")\n",
        "        torch.save(self.target_net.state_dict(), f\"{self.base_filename}.target.net\")\n",
        "        self.memory.save(f\"{self.base_filename}.memory\")\n",
        "\n",
        "    def load(self):\n",
        "        self.memory = ReplayMemory(self.buffer_size, self.batch_size, self.device, f\"{self.base_filename}.memory\", top=self.memoryTop)\n",
        "        self.policy_net.load_state_dict(torch.load(f\"{self.base_filename}.policy.net\"))\n",
        "        self.target_net.load_state_dict(torch.load(f\"{self.base_filename}.target.net\"))\n",
        "\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        # Save experience in replay memory\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "        \n",
        "        # Learn every \"learn_every\" time steps.\n",
        "        self.time_step = (self.time_step + 1) % self.learn_every\n",
        "        if self.time_step == 0:\n",
        "            # If enough samples are available in memory, get random subset and learn\n",
        "            if len(self.memory) > self.replay_after:\n",
        "                experiences = self.memory.sample()\n",
        "                self.learn(experiences)\n",
        "\n",
        "\n",
        "    def act(self, state, eps=0.):\n",
        "        if torch.rand(1).item() < eps: # Epsilon-greedy action selection\n",
        "            return torch.randint(self.action_size, (1,)).item(), 2\n",
        "        \n",
        "        self.policy_net.eval() # set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            state = torch.from_numpy(state).unsqueeze(0).to(self.device)\n",
        "            action_values = self.policy_net(state)\n",
        "            action_selection = action_values.detach().argmax().cpu().numpy()\n",
        "        self.policy_net.train() # set the model back to training mode\n",
        "        return action_selection, 1\n",
        "            \n",
        "    def learn(self, experiences): #input = 1 mini-batch\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "        # Get expected Q values from the policy, and max predicted Q values from the target\n",
        "        Q_expected = self.policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
        "        targets_next = self.target_net(next_states).detach().max(dim=1)[0]\n",
        "        \n",
        "        # Calculate the Q value\n",
        "        # Multiply by (1 - done) to zero out the next state Q values if the game ended.\n",
        "        Q_targets = rewards + (self.gamma * targets_next * (1 - dones))\n",
        "        \n",
        "        # optimise the model, by minimising the loss\n",
        "        loss = self.loss(Q_expected, Q_targets)\n",
        "        self.losses[self.nextLossIdx.item()] = loss\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.soft_update(self.policy_net, self.target_net, self.tau)\n",
        "\n",
        "    \n",
        "    # θ'=θ×τ+θ'×(1−τ)\n",
        "    def soft_update(self, policy_model, target_model, tau):\n",
        "        for target_param, policy_param in zip(target_model.parameters(), policy_model.parameters()):\n",
        "            target_param.data.copy_(tau*policy_param.data + (1.0-tau)*target_param.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj38QqcR2tw1"
      },
      "source": [
        "### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IuCDHnnL2M8i"
      },
      "outputs": [],
      "source": [
        "def epsilon_decrease_func(start, end, decay):\n",
        "    def epsilon_decrease(i):\n",
        "        return end + (start - end) * math.exp(-1. * i / decay)\n",
        "    return epsilon_decrease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nNC_i9PE1TiX"
      },
      "outputs": [],
      "source": [
        "def trainDQN(agent: DQNAgent, epsilon_decrease, env, n_episodes=1000, network='DQNcnn', start_epoch = 0, save_every=100, plot_every=500, log_eps=False):\n",
        "    print(f\"Training for {n_episodes} episodes, train every {agent.learn_every} episodes = {int(n_episodes/agent.learn_every)} train epoch\")\n",
        "    scores = []\n",
        "    stack_frames = get_stack_frames(network)\n",
        "    for i_episode in range(start_epoch + 1, start_epoch + n_episodes + 1):\n",
        "        state = stack_frames(None, env.reset(), is_new=True)\n",
        "        score, done = 0, False\n",
        "        eps = epsilon_decrease(i_episode)\n",
        "        while not done:\n",
        "            action, _ = agent.act(state, eps)\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            score += reward\n",
        "            next_state = stack_frames(state, next_state, is_new=False)\n",
        "            agent.step(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "        scores.append(score)\n",
        "\n",
        "        print(f'\\rEpisode {i_episode}\\tScore: {scores[-1]}\\tAverage Score: {round(np.mean(scores[-20:]), 2)}\\t eps:{round(eps, 2)}\\t ', end=\"\") #log_eps_str\n",
        "        \n",
        "        if i_episode % plot_every == 0:\n",
        "            print(f'\\rEpisode {i_episode}\\tAverage Score: {np.mean(scores[-plot_every:])}')\n",
        "            _ = plt.hist(scores[-plot_every:], bins=30)\n",
        "            plt.show()\n",
        "            evalDQN(agent, 0.1, n_episodes=50,  network=network)\n",
        "        if i_episode % save_every == 0:\n",
        "            agent.save()\n",
        "    agent.save()\n",
        "    return scores\n",
        "\n",
        "def evalDQN(agent, eps, env, n_episodes=50,  network='DQNcnn'):\n",
        "    scores = []\n",
        "    stack_frames = get_stack_frames(network)\n",
        "    high_score, high_score_action_types = 0, (0.0,0.0)\n",
        "    for i_episode in range(n_episodes):\n",
        "        state = stack_frames(None, env.reset(), is_new=True)\n",
        "        score, done = 0, False\n",
        "        actionTypes, actionTypesIdx = np.zeros(50000, dtype=np.uint8), 0\n",
        "        while not done:\n",
        "            action, actionType = agent.act(state, eps)\n",
        "            actionTypes[actionTypesIdx] = actionType\n",
        "            actionTypesIdx += 1\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            score += reward\n",
        "            state = stack_frames(state, next_state, is_new=False)\n",
        "        scores.append(score)\n",
        "        if score > high_score:\n",
        "            high_score = score\n",
        "            high_score_action_types = (np.count_nonzero(actionTypes == 2)/actionTypesIdx, np.count_nonzero(actionTypes == 1)/actionTypesIdx) \n",
        "        log_eps_str = f'rand({round(np.count_nonzero(actionTypes[actionTypes == 2])/actionTypesIdx,2)}) neural({round(np.count_nonzero(actionTypes[actionTypes == 1])/actionTypesIdx,2)})    '\n",
        "        print(f'\\rEpisode {i_episode+1}\\tScore: {round(scores[-1])}\\tAverage Score: {round(np.mean(scores[-n_episodes:]), 1)}\\t eps:{round(eps, 2)}\\t {log_eps_str}', end=\"\")\n",
        "    print(f'\\n eval:\\navg score: {np.mean(scores)}  high score: {np.max(scores)} low score: {np.min(scores)}')\n",
        "    iqr25, iqr75, iqrAvg = iqr_mean(scores)\n",
        "    print(f\"interquatile range ({iqr25} -> {iqr75}) mean = {round(iqrAvg, 2)}\")\n",
        "    print(f'high score: {high_score}, rand: {round(high_score_action_types[0]*100, 1)}% neural net: {round(high_score_action_types[1]*100,1)}%')\n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw-odSlqxgP8"
      },
      "source": [
        "### run train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Vxf8Qb6Nndf2"
      },
      "outputs": [],
      "source": [
        "model = 'DQNcnn' # options are 'DQNcnn' or 'ResNetDQN'\n",
        "\n",
        "Number_of_episodes = 20000\n",
        "save_models_every = 250\n",
        "train_every = 20\n",
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx6Xu8kRndf2"
      },
      "source": [
        "#### training runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "8OuNTFsI3C_z",
        "outputId": "a3fdcd9e-8055-4e8c-c221-ae43098ed536"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/users/sgmsempl/.conda/envs/torch/lib/python3.9/site-packages/gym/wrappers/record_video.py:41: UserWarning: \u001b[33mWARN: Overwriting existing videos at /users/sgmsempl/video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "env = wrap_env(gym.make(env_name), record_every=1000)\n",
        "\n",
        "agent_args = {\n",
        "            'input_shape': (4, frame_crops[model], frame_crops[model]),\n",
        "            'action_size': env.action_space.n,\n",
        "            'device': device,\n",
        "            'buffer_size': 1000000,\n",
        "            'batch_size': 64,\n",
        "            'gamma': 0.99,\n",
        "            'lr': 1e-4,\n",
        "            'tau': 1e-3,\n",
        "            'learn_every': train_every,\n",
        "            'replay_after': 10000,\n",
        "            'memory_top': 0.25,\n",
        "            'episodes': Number_of_episodes\n",
        "        }\n",
        "\n",
        "if model == 'DQNcnn':\n",
        "    agent_args = {**agent_args, 'model': DQNCnn, 'base_filename': 'atari_atlantas_models1-Copy1'}\n",
        "elif model == 'ResNetDQN':\n",
        "    agent_args = {**agent_args, 'model': ResNetDQN, 'base_filename': 'atari_models/atari_atlantas_resnet'}\n",
        "else:\n",
        "    raise Exception('model not found')\n",
        "\n",
        "epsilon_decrease = epsilon_decrease_func(start=0.9, end=0.02, decay=Number_of_episodes/2)\n",
        "# epsilon_decrease = lambda x: 0.05\n",
        "plot_epsilon_func(epsilon_decrease, Number_of_episodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3DpdbkZndf3"
      },
      "source": [
        "#### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0728594651227902\n"
          ]
        }
      ],
      "source": [
        "Number_of_episodes = 5000\n",
        "\n",
        "epsilon_decrease = epsilon_decrease_func(start=0.7, end=0.04, decay=Number_of_episodes/3)\n",
        "plot_epsilon_func(epsilon_decrease, Number_of_episodes)\n",
        "print(epsilon_decrease(Number_of_episodes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# agent = DQNAgent(agent_args)\n",
        "# agent.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "2XfmuL5rndf4",
        "outputId": "8b896933-73de-4b12-dd79-4485999216bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " eval:\n",
            "avg score: 5036.0  high score: 16800.0\n",
            "high score: 16800.0, rand: 0.11026200873362445 nnural: 0.8897379912663755\n"
          ]
        }
      ],
      "source": [
        "\n",
        "agent = DQNAgent(agent_args)\n",
        "agent.load()\n",
        "scores = trainDQN(agent, epsilon_decrease, env, n_episodes=Number_of_episodes, save_every=save_models_every, plot_every=1000, network=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/users/sgmsempl/.conda/envs/torch/lib/python3.9/site-packages/gym/wrappers/record_video.py:41: UserWarning: \u001b[33mWARN: Overwriting existing videos at /users/sgmsempl/eval_videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 49\tScore: 13100\tAverage Score: 13244.0\t eps:0.2\t rand(0.21) neural(0.79)     eval:\n",
            "avg score: 13244.0  high score: 23700.0 low score: 2700.0\n",
            "interquatile range (9125.0 -> 17000.0) mean = 12983.33\n",
            "high score: 23700.0, rand: 20.9% neural net: 79.1%\n"
          ]
        }
      ],
      "source": [
        "env = wrap_env(gym.make(env_name), record_every=1000, folder='./eval_videos')\n",
        "agent = DQNAgent(agent_args)\n",
        "agent.load()\n",
        "evalScores = evalDQN(agent, 0.15, env, n_episodes=50,  network=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nDIRbuQUndf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9125.0, 17000.0, 12983.333333333334, 13244.0, 23700.0)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "_ = plt.hist(evalScores, bins=10)\n",
        "*iqr_mean(evalScores), np.mean(evalScores), np.max(evalScores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xzRetiqKndf-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 49\tScore: 6800\tAverage Score: 10006.0\t eps:0.15\t rand(0.13) neural(0.87)     eval:\n",
            "avg score: 10006.0  high score: 18500.0 low score: 4000.0\n",
            "interquatile range (7525.0 -> 12025.0) mean = 9454.17\n",
            "high score: 18500.0, rand: 15.1% neural net: 84.9%\n"
          ]
        }
      ],
      "source": [
        "evalScores15 = evalDQN(agent, 0.15, env, n_episodes=50,  network=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 50\tScore: 8700\tAverage Score: 6420.0\t eps:0.08\t rand(0.1) neural(0.9)       \n",
            " eval:\n",
            "avg score: 6420.0  high score: 14500.0 low score: 2000.0\n",
            "interquatile range (4500.0 -> 7975.0) mean = 6330.43\n",
            "high score: 14500.0, rand: 7.8% neural net: 92.2%\n"
          ]
        }
      ],
      "source": [
        "evalScores10 = evalDQN(agent, 0.08, env, n_episodes=50,  network=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE-yFm4M4DoR"
      },
      "outputs": [],
      "source": [
        "def finalPlay(agent):\n",
        "    env = wrap_env(gym.make(env_name))\n",
        "    score = 0\n",
        "    state = stack_frames(None, env.reset(), True)\n",
        "    while True:\n",
        "        # env.render()\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        score += reward\n",
        "        state = stack_frames(state, next_state)\n",
        "        if done:\n",
        "            print(\"You Final score is:\", score)\n",
        "            break \n",
        "    env.close()\n",
        "finalPlay(agent)\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyBB-sqS3F0i"
      },
      "source": [
        "### DQN2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeDcleB_WV2W"
      },
      "outputs": [],
      "source": [
        "class DQN2(nn.Module):\n",
        "    def __init__(self, h, w, outputs):\n",
        "        super(DQN2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Number of Linear input connections depends on output of conv2d layers\n",
        "        # and therefore the input image size, so compute it.\n",
        "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
        "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
        "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
        "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
        "        linear_input_size = convw * convh * 32\n",
        "        self.head = nn.Linear(linear_input_size, outputs)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        print(\"in size\", x.size())\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        print(\"2 size\", x.size())\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        print(\"3 size\", x.size())\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        return self.head(x.view(x.size(0), -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_bgOQObndgD"
      },
      "outputs": [],
      "source": [
        "def get_output_size(in_size, kernel_size, stride=1, padding=0):\n",
        "    integer = int((in_size - kernel_size + 2 * padding) / stride) == ((in_size - kernel_size + 2 * padding) / stride)\n",
        "    if not integer:\n",
        "        print(\"not int\", ((in_size - kernel_size + 2 * padding) / stride))\n",
        "    return int((in_size - kernel_size + 2 * padding) / stride) + 1\n",
        "\n",
        "get_output_size(in_size=84, kernel_size=3, stride=2, padding=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqqu-qq39Swm"
      },
      "outputs": [],
      "source": [
        "class DQNtst(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "        #in = 299x299\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=0), #out = 149x149\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            # nn.Dropout(0.3),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0), #out = 147x147\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), #out = 147x147\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0) #out = 73x73                    \n",
        "        )\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "                  nn.Linear(state_space_dim,64),\n",
        "                  nn.ReLU(),\n",
        "                  nn.Linear(64,64*2),\n",
        "                  nn.ReLU(),\n",
        "                  nn.Linear(64*2,action_space_dim)\n",
        "                )\n",
        "# (33600x3 and 210x64)\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        print('in size=', x.size())\n",
        "        x = self.block1(x)\n",
        "        print('block1 size=', x.size())\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRwZZtBSS4ti"
      },
      "outputs": [],
      "source": [
        "class DQNCnn(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "        \n",
        "        self.features = nn.Sequential( # in = 84x84\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        ) # out = 7x7\n",
        "        self.feature_size = 7 * 7 * 64\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.feature_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.num_actions)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bfd5JgWoICcg",
        "zyBEYPP0H-qS",
        "yeaT5VbKKpSE"
      ],
      "include_colab_link": true,
      "name": "working.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "967264ae980203440ddaee0507bc3cd46af5e06b6d5472ede725bb9edfce0d78"
    },
    "kernelspec": {
      "display_name": "Python [conda env:root] *",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
