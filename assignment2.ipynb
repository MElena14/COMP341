{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MElena14/COMP341/blob/main/assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfd5JgWoICcg"
      },
      "source": [
        "#### imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k3dxF3QaJqeD"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "from collections import deque,namedtuple\n",
        "# import cv2\n",
        "import pickle\n",
        "# from tqdm.notebook import tqdm\n",
        "import PIL\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# import gym\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyBEYPP0H-qS"
      },
      "source": [
        "#### Render OpenAI Gym Environments from CoLab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "AL2uvFBoH4ji",
        "outputId": "4238a76d-4f8d-48ff-c34b-b1af70f9ff7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "not in colab\n",
            "Using device cuda:1\n"
          ]
        }
      ],
      "source": [
        "# HIDE OUTPUT\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
        "    env_name = \"Atlantis-v0\"\n",
        "    !wget http://www.atarimania.com/roms/Roms.rar \n",
        "    !unrar x -o+ /content/Roms.rar >/dev/nul\n",
        "    !python -m atari_py.import_roms /content/ROMS >/dev/nul\n",
        "\n",
        "    !pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "    !apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "\n",
        "    !apt-get update > /dev/null 2>&1\n",
        "    !apt-get install cmake > /dev/null 2>&1\n",
        "    !pip install --upgrade setuptools 2>&1\n",
        "    !pip install ez_setup > /dev/null 2>&1\n",
        "    !pip install gym[atari] > /dev/null 2>&1\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    env_name = \"ALE/Atlantis-v5\"\n",
        "    print('not in colab')\n",
        "    device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:1\")\n",
        "print(\"Using device\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjkT6v3pHnVv",
        "outputId": "5927ff8d-d5de-46f3-f192-70708746f48f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action Space: Discrete(4)\n",
            "possible actions: ['NOOP', 'FIRE', 'RIGHTFIRE', 'LEFTFIRE']\n",
            "Observation Space: Box(0, 255, (210, 160, 3), uint8)\n",
            "Max Episode Steps: 27000\n",
            "Nondeterministic: False\n",
            "Reward Range: (-inf, inf)\n",
            "Reward Threshold: None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
            "[Powered by Stella]\n"
          ]
        }
      ],
      "source": [
        "def query_environment(name):\n",
        "  env = gym.make(name)\n",
        "  spec = gym.spec(name)\n",
        "  print(f\"Action Space: {env.action_space}\")\n",
        "  print(f\"possible actions: {env.unwrapped.get_action_meanings()}\")\n",
        "  print(f\"Observation Space: {env.observation_space}\")\n",
        "  print(f\"Max Episode Steps: {spec.max_episode_steps}\")\n",
        "  print(f\"Nondeterministic: {spec.nondeterministic}\")\n",
        "  print(f\"Reward Range: {env.reward_range}\")\n",
        "  print(f\"Reward Threshold: {spec.reward_threshold}\")\n",
        "  \n",
        "query_environment(env_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8X-yeVrRHpTf"
      },
      "outputs": [],
      "source": [
        "\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "# display = Display(visible=0, size=(1400, 900))\n",
        "# display.start()\n",
        "\n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment \n",
        "and displaying it.\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  print(mp4list[-1])\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[-1]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "if IN_COLAB:\n",
        "    from gym.wrappers import Monitor\n",
        "    def wrap_env(env, record_every=1):\n",
        "        env = Monitor(env, './video', force=True)\n",
        "        return env\n",
        "else:\n",
        "    from gym.wrappers.record_video import RecordVideo\n",
        "    def wrap_env(env, record_every=1):\n",
        "        env = RecordVideo(env, './video', episode_trigger=lambda i: i % record_every == 0)\n",
        "        return env\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvpErA1hITFs"
      },
      "source": [
        "#### inital random agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AVzkJJHendfi"
      },
      "outputs": [],
      "source": [
        "def show_random_agent():\n",
        "  env = wrap_env(gym.make(env_name))\n",
        "\n",
        "  observation = env.reset()\n",
        "  score = 0\n",
        "  while True:\n",
        "      env.render()\n",
        "      action = env.action_space.sample()\n",
        "      observation, reward, done, info = env.step(action)\n",
        "      score += reward\n",
        "      if done:\n",
        "        print(f\"finished! random agent's score is {score}\")\n",
        "        break\n",
        "  env.close()\n",
        "  show_video()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkV2DFe4JwC9"
      },
      "source": [
        "#### Deep QN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Mx-ZVJ4s4nV_"
      },
      "outputs": [],
      "source": [
        "class DQNCnn(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "        \n",
        "        self.features = nn.Sequential( # in = 84x84\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        ) # out = 7x7\n",
        "        self.feature_size = 7 * 7 * 64\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.feature_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.num_actions)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg5IwV9Gndfl"
      },
      "source": [
        "#### ResNetDQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krpJGCQ-ndfl"
      },
      "source": [
        "##### ResNetBlock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SsP2JnGWndfm"
      },
      "outputs": [],
      "source": [
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, depth_in, activation_func, depth_out=-1):\n",
        "        super().__init__()\n",
        "        self.downSampleResidul = True\n",
        "        if depth_out == -1:\n",
        "            depth_out = depth_in\n",
        "            self.downSampleResidul = False\n",
        "\n",
        "        self.resBlock = nn.Sequential(\n",
        "            nn.BatchNorm2d(depth_in),\n",
        "            activation_func(inplace=True),\n",
        "            nn.Conv2d(depth_in, depth_out, kernel_size=3, padding=1, stride=1 if not self.downSampleResidul else 2, bias=False),\n",
        "            nn.BatchNorm2d(depth_out),\n",
        "            activation_func(inplace=True),\n",
        "            nn.Conv2d(depth_out, depth_out, kernel_size=3, padding=1, bias=False)\n",
        "        )\n",
        "\n",
        "        self.downsampleRes = nn.Sequential(\n",
        "            nn.BatchNorm2d(depth_in),\n",
        "            activation_func(inplace=True),\n",
        "            nn.Conv2d(depth_in, depth_out, kernel_size=1, stride=2, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.resBlock(x)\n",
        "        if self.downSampleResidul:\n",
        "            x = self.downsampleRes(x)\n",
        "        return z + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPg5kxuundfn",
        "outputId": "2edfdf27-7973-4d6c-8645-fc33d9cf2687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "not int 9.5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_cnn_output_size(in_size, kernel_size, stride=1, padding=0):\n",
        "    integer = int((in_size - kernel_size + 2 * padding) / stride) == ((in_size - kernel_size + 2 * padding) / stride)\n",
        "    if not integer:\n",
        "        print(\"not int\", ((in_size - kernel_size + 2 * padding) / stride))\n",
        "    return int((in_size - kernel_size + 2 * padding) / stride) + 1\n",
        "get_cnn_output_size(in_size=20, kernel_size=3, stride=2, padding=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTcVbQMrndfo"
      },
      "source": [
        "##### ResNetDQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9zx6rGfDndfp"
      },
      "outputs": [],
      "source": [
        "class ResNetDQN(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "        super(ResNetDQN, self).__init__()\n",
        "        #in = 159x159\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 16, kernel_size=3, stride=2, padding=0), #out = 79x79\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0), #out = 77x77\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0), #out = 75x75\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=0) #out = 37x37\n",
        "        )\n",
        "        \n",
        "        self.featureExtractionBlock = nn.Sequential(\n",
        "            ResNetBlock(32, nn.SiLU, 64),  #out = 19x19\n",
        "            ResNetBlock(64, nn.SiLU),      #out = 19x19\n",
        "            ResNetBlock(64, nn.SiLU),      #out = 19x19 \n",
        "            ResNetBlock(64, nn.SiLU, 128), #out = 10x10\n",
        "            ResNetBlock(128, nn.SiLU),     #out = 10x10\n",
        "        )\n",
        "        # self.pool = nn.AdaptiveAvgPool2d((4,4))\n",
        "        self.flattened_size = 128 * 10 * 10\n",
        "        self.regressionBlock = nn.Sequential(\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(self.flattened_size, 1024),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.Linear(1024, self.num_actions),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.featureExtractionBlock(x)\n",
        "        # x = self.pool(x)\n",
        "        x = x.view(-1, self.flattened_size)\n",
        "        x = self.regressionBlock(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSFkzLbg0p7q"
      },
      "source": [
        "#### utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "uS4Ms1_30tbT",
        "outputId": "3dd6f4ca-7ad1-4481-d2b0-0a4f33a5262c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJ8AAACfCAAAAADCcFQ8AAABIElEQVR4nO3asUrDUBiG4e/QioixOIhQUClaQcRFN0HHXorQG+jYW+gtWOhaRy+m6OAgDopI1ZpYi3WoIC2hQ/5zCNj3WXKmn5ck52SJBAAAAAAAgJCcjyGFSH0fc0KpdrvLgUYX7SN2D9Zu9G2fk8rat7Wkw2N9qHL35aVnlvX9a5V/F417a0qqrPfvYm9y3e4cxQ/n7Wbz0VvSlKx9yUBSoaJB8p7Er8OXME/X+Hyj+t/68tmaksrU50rS2aakz2u9hdnBpv077ku3riSNNhQPfSVNMZ9/vdUVSSd6CtNn/765yYhQBzQAAAAAAAAAAAAAAACycKH+B/Rk5yrvgvmiWt4FAAAAAAAAAAAAAAAsjNP9vAvmK6/nXQAAwH/0A3MoLJGS4OtSAAAAAElFTkSuQmCC",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=159x159 at 0x7F6EA82D2430>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# taken from https://github.com/deepanshut041/Reinforcement-Learning/blob/master/algos/preprocessing/stack_frame.py\n",
        "def preprocess_frame(screen, exclude, output):\n",
        "    \"\"\"Preprocess Image.\n",
        "        \n",
        "        Params\n",
        "        ======\n",
        "            screen (array): RGB Image\n",
        "            exclude (tuple): Section to be croped (UP, RIGHT, DOWN, LEFT)\n",
        "            output (int): Size of output image\n",
        "        \"\"\"\n",
        "    # TConver image to gray scale\n",
        "    screen = cv2.cvtColor(screen, cv2.COLOR_RGB2GRAY)\n",
        "    \n",
        "    #Crop screen[Up: Down, Left: right] \n",
        "    screen = screen[exclude[0]:exclude[2], exclude[3]:exclude[1]]\n",
        "    \n",
        "    # Convert to float, and normalized\n",
        "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
        "    \n",
        "    # Resize image to 84 * 84\n",
        "    screen = cv2.resize(screen, (output, output), interpolation = cv2.INTER_AREA)\n",
        "    return screen\n",
        "\n",
        "def stack_frame(stacked_frames, frame, is_new):\n",
        "    \"\"\"Stacking Frames.\n",
        "        \n",
        "        Params\n",
        "        ======\n",
        "            stacked_frames (array): Four Channel Stacked Frame\n",
        "            frame: Preprocessed Frame to be added\n",
        "            is_new: Is the state First\n",
        "        \"\"\"\n",
        "    if is_new:\n",
        "        stacked_frames = np.stack(arrays=[frame, frame, frame, frame])\n",
        "        stacked_frames = stacked_frames\n",
        "    else:\n",
        "        stacked_frames[0] = stacked_frames[1]\n",
        "        stacked_frames[1] = stacked_frames[2]\n",
        "        stacked_frames[2] = stacked_frames[3]\n",
        "        stacked_frames[3] = frame\n",
        "    \n",
        "    return stacked_frames\n",
        "\n",
        "frame_crops = {'DQNcnn': 84, 'ResNetDQN': 159}\n",
        "\n",
        "def get_stack_frames(net='DQNcnn'):\n",
        "    size = frame_crops[net]\n",
        "    def stack_frames(frames, state, is_new=False):\n",
        "        frame = preprocess_frame(state, (0, -10, -100, 9), size)\n",
        "        frames = stack_frame(frames, frame, is_new)\n",
        "        return frames\n",
        "    return stack_frames\n",
        "\n",
        "def show_cropped_image():\n",
        "    env = gym.make(env_name)\n",
        "    observation = env.reset()\n",
        "    t, done = 0, False\n",
        "    while not done and t < 260:\n",
        "      # env.render()\n",
        "      action = env.action_space.sample() \n",
        "      observation, reward, done, info = env.step(action)\n",
        "      \n",
        "      t += 1\n",
        "                                # (UP, RIGHT, DOWN, LEFT)\n",
        "    f = preprocess_frame(observation, (0, -10, -100, 9), 159)\n",
        "    return PIL.Image.fromarray(np.uint8(f * 255), mode=\"L\")\n",
        "show_cropped_image()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gQK4tV3qndfu"
      },
      "outputs": [],
      "source": [
        "def plot_epsilon_func(eps_func, n_episodes=1000):\n",
        "    episodes = range(n_episodes)\n",
        "    eps = [eps_func(i) for i in episodes]\n",
        "    plt.plot(episodes, eps)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtzA_Zt7tTOs"
      },
      "source": [
        "### memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "W14ncSaOKCVj"
      },
      "outputs": [],
      "source": [
        "# Experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "from numpy.typing import NDArray\n",
        "class ReplayMemory:\n",
        "    def __init__(self, buffer_size, batch_size, device, filename=None, top=1):\n",
        "        self.memory = deque(maxlen=buffer_size) if filename is None else pickle.load(open(filename, 'rb'))\n",
        "        self.batch_size = int(batch_size/top) if top < 1 else batch_size\n",
        "        self.top = top\n",
        "        self.device = device\n",
        "        self.mean = lambda l: sum(l)/len(l)\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        Experience = (state, action, reward, next_state, float(done))\n",
        "        self.memory.append(Experience)\n",
        "    def _as_tensor(self, np_array:NDArray, dtype=torch.float):\n",
        "        tensor = torch.from_numpy(np.array(np_array))\n",
        "        return tensor.type(dtype, non_blocking=True).to(self.device, non_blocking=True)\n",
        "    def sample(self):\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "        if self.top < 1:\n",
        "            experiences.sort(key=lambda e:e[2])\n",
        "            experiences = experiences[int((self.top*self.batch_size)-1):int(self.batch_size-1)]\n",
        "        states, actions, rewards, next_states, dones = zip(*experiences)\n",
        "        states, next_states = self._as_tensor(states), self._as_tensor(next_states)\n",
        "        actions, rewards, dones = self._as_tensor(actions, dtype=torch.int64), self._as_tensor(rewards), self._as_tensor(dones, dtype=torch.uint8)\n",
        "        return (states, actions, rewards, next_states, dones)\n",
        "        \n",
        "\n",
        "    def save(self, filename):\n",
        "        pickle.dump(self.memory, open(filename, 'wb') )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YLCgDIQ1RfH"
      },
      "source": [
        "### Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_SOXNZ20yFQ4"
      },
      "outputs": [],
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, args):\n",
        "        \"\"\"\n",
        "        args = {\n",
        "            input_shape:  (tuple) dimension of each state (C, H, W)\n",
        "            action_size (int): dimension of each action\n",
        "            seed (int): random seed\n",
        "            device(string): Use Gpu or CPU\n",
        "            buffer_size (int): replay buffer size\n",
        "            batch_size (int):  torch minibatch size\n",
        "            gamma (float): discount factor\n",
        "            lr (float): learning rate \n",
        "            update_every (int): how often to update the network\n",
        "            replay_after (int): After which replay to be started\n",
        "            model(Model): Pytorch Model\n",
        "            base_filename (str): base filename to save models to\n",
        "        }\n",
        "        \"\"\"\n",
        "        self.input_shape = args['input_shape']\n",
        "        self.action_size = args['action_size']\n",
        "        self.device = args['device']\n",
        "        self.buffer_size = args['buffer_size']\n",
        "        self.batch_size = args['batch_size']\n",
        "        self.gamma = args['gamma']\n",
        "        self.lr = args['lr']\n",
        "        self.learn_every = args['learn_every']\n",
        "        self.replay_after = args['replay_after']\n",
        "        self.network = args['model']\n",
        "        self.tau = args['tau']\n",
        "        self.base_filename = args['base_filename']\n",
        "        episodes = args['episodes'] if 'episodes' in args else 10000\n",
        "        \n",
        "        \n",
        "        # Q-Network\n",
        "        self.policy_net = self.network(self.input_shape, self.action_size).to(self.device)\n",
        "        self.target_net = self.network(self.input_shape, self.action_size).to(self.device)\n",
        "        self.optimizer = torch.optim.AdamW(self.policy_net.parameters(), lr=self.lr, )\n",
        "        self.loss = nn.SmoothL1Loss()\n",
        "        self.losses = torch.zeros(int(episodes/self.learn_every+2)).to(self.device)\n",
        "        self.nextLossIdx = torch.tensor([0],dtype=torch.uint8).to(self.device)\n",
        "\n",
        "        self.memoryTop = args['memory_top'] if 'memory_top' in args else False\n",
        "        self.memory = ReplayMemory(self.buffer_size, self.batch_size, self.device, top=self.memoryTop)\n",
        "        \n",
        "        self.time_step = 0\n",
        "\n",
        "    def save(self):\n",
        "        torch.save(self.policy_net.state_dict(), f\"{self.base_filename}.policy.net\")\n",
        "        torch.save(self.target_net.state_dict(), f\"{self.base_filename}.target.net\")\n",
        "        self.memory.save(f\"{self.base_filename}.memory\")\n",
        "\n",
        "    def load(self):\n",
        "        self.memory = ReplayMemory(self.buffer_size, self.batch_size, self.device, f\"{self.base_filename}.memory\", top=self.memoryTop)\n",
        "        self.policy_net.load_state_dict(torch.load(f\"{self.base_filename}.policy.net\"))\n",
        "        self.target_net.load_state_dict(torch.load(f\"{self.base_filename}.target.net\"))\n",
        "\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        # Save experience in replay memory\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "        \n",
        "        # Learn every \"learn_every\" time steps.\n",
        "        self.time_step = (self.time_step + 1) % self.learn_every\n",
        "        if self.time_step == 0:\n",
        "            # If enough samples are available in memory, get random subset and learn\n",
        "            if len(self.memory) > self.replay_after:\n",
        "                experiences = self.memory.sample()\n",
        "                self.learn(experiences)\n",
        "\n",
        "\n",
        "    def act(self, state, eps=0.):\n",
        "        if torch.rand(1).item() < eps: # Epsilon-greedy action selection\n",
        "            return torch.randint(self.action_size, (1,)).item(), 2\n",
        "        \n",
        "        self.policy_net.eval() # set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            state = torch.from_numpy(state).unsqueeze(0).to(self.device)\n",
        "            action_values = self.policy_net(state)\n",
        "            action_selection = action_values.detach().argmax().cpu().numpy()\n",
        "        self.policy_net.train() # set the model back to training mode\n",
        "        return action_selection, 1\n",
        "            \n",
        "    def learn(self, experiences): #input = 1 mini-batch\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "        # Get expected Q values from the policy, and max predicted Q values from the target\n",
        "        Q_expected = self.policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
        "        targets_next = self.target_net(next_states).detach().max(dim=1)[0]\n",
        "        \n",
        "        # Calculate the Q value\n",
        "        # Multiply by (1 - done) to zero out the next state Q values if the game ended.\n",
        "        Q_targets = rewards + (self.gamma * targets_next * (1 - dones))\n",
        "        \n",
        "        # optimise the model, by minimising the loss\n",
        "        loss = self.loss(Q_expected, Q_targets)\n",
        "        self.losses[self.nextLossIdx.item()] = loss\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.soft_update(self.policy_net, self.target_net, self.tau)\n",
        "\n",
        "    \n",
        "    # θ'=θ×τ+θ'×(1−τ)\n",
        "    def soft_update(self, policy_model, target_model, tau):\n",
        "        for target_param, policy_param in zip(target_model.parameters(), policy_model.parameters()):\n",
        "            target_param.data.copy_(tau*policy_param.data + (1.0-tau)*target_param.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj38QqcR2tw1"
      },
      "source": [
        "### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IuCDHnnL2M8i"
      },
      "outputs": [],
      "source": [
        "def epsilon_decrease_func(start, end, decay):\n",
        "    def epsilon_decrease(i):\n",
        "        return end + (start - end) * math.exp(-1. * i / decay)\n",
        "    return epsilon_decrease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nNC_i9PE1TiX"
      },
      "outputs": [],
      "source": [
        "def trainDQN(agent: DQNAgent, epsilon_decrease, n_episodes=1000, network='DQNcnn', start_epoch = 0, save_every=100, plot_every=500, log_eps=False):\n",
        "    print(f\"Training for {n_episodes} episodes, train every {agent.learn_every} episodes = {int(n_episodes/agent.learn_every)} train epoch\")\n",
        "    scores = []\n",
        "    stack_frames = get_stack_frames(network)\n",
        "    for i_episode in range(start_epoch + 1, start_epoch + n_episodes + 1):\n",
        "        state = stack_frames(None, env.reset(), is_new=True)\n",
        "        score, done = 0, False\n",
        "        eps = epsilon_decrease(i_episode)\n",
        "        while not done:\n",
        "            action, _ = agent.act(state, eps)\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            score += reward\n",
        "            next_state = stack_frames(state, next_state, is_new=False)\n",
        "            agent.step(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "        scores.append(score)\n",
        "\n",
        "        print(f'\\rEpisode {i_episode}\\tScore: {scores[-1]}\\tAverage Score: {round(np.mean(scores[-20:]), 2)}\\t eps:{round(eps, 2)}\\t ', end=\"\") #log_eps_str\n",
        "        \n",
        "        if i_episode % plot_every == 0:\n",
        "            print(f'\\rEpisode {i_episode}\\tAverage Score: {np.mean(scores[-plot_every:])}')\n",
        "            _ = plt.hist(scores[-plot_every:], bins=30)\n",
        "            plt.show()\n",
        "            evalDQN(agent, 0.1, n_episodes=50,  network=network)\n",
        "        if i_episode % save_every == 0:\n",
        "            agent.save()\n",
        "    agent.save()\n",
        "    return scores\n",
        "\n",
        "def evalDQN(agent, eps, n_episodes=50,  network='DQNcnn'):\n",
        "    scores = []\n",
        "    stack_frames = get_stack_frames(network)\n",
        "    high_score, high_score_action_types = 0, (0.0,0.0)\n",
        "    for i_episode in range(n_episodes):\n",
        "        state = stack_frames(None, env.reset(), is_new=True)\n",
        "        score, done = 0, False\n",
        "        actionTypes, actionTypesIdx = np.zeros(50000, dtype=np.uint8), 0\n",
        "        while not done:\n",
        "            action, actionType = agent.act(state, eps)\n",
        "            actionTypes[actionTypesIdx] = actionType\n",
        "            actionTypesIdx += 1\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "            score += reward\n",
        "            state = stack_frames(state, next_state, is_new=False)\n",
        "        scores.append(score)\n",
        "        if score > high_score:\n",
        "            high_score = score\n",
        "            high_score_action_types = (np.count_nonzero(actionTypes == 2)/actionTypesIdx, np.count_nonzero(actionTypes == 1)/actionTypesIdx) \n",
        "#         log_eps_str = f'rand({round(np.count_nonzero(actionTypes[actionTypes == 2])/actionTypesIdx,2)}) nural({round(np.count_nonzero(actionTypes[actionTypes == 1])/actionTypesIdx,2)})    '\n",
        "#         print(f'\\rEpisode {i_episode}\\tScore: {scores[-1]}\\tAverage Score: {round(np.mean(scores[-n_episodes:]), 2)}\\t eps:{round(eps, 2)}\\t {log_eps_str}', end=\"\")\n",
        "    print(f' eval:\\navg score: {np.mean(scores)}  high score: {np.max(scores)}')\n",
        "    print(f'high score: {high_score}, rand: {high_score_action_types[0]} nnural: {high_score_action_types[1]}')\n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw-odSlqxgP8"
      },
      "source": [
        "### run train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Vxf8Qb6Nndf2"
      },
      "outputs": [],
      "source": [
        "model = 'ResNetDQN' # options are 'DQNcnn' or 'ResNetDQN'\n",
        "\n",
        "Number_of_episodes = 8000\n",
        "save_models_every = 250\n",
        "train_every = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx6Xu8kRndf2"
      },
      "source": [
        "#### training runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "Number_of_episodes = 3000\n",
        "epsilon_decrease = epsilon_decrease_func(start=0.2, end=0.08, decay=Number_of_episodes/2)\n",
        "# epsilon_decrease = lambda x: 0.1\n",
        "plot_epsilon_func(epsilon_decrease, Number_of_episodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "8OuNTFsI3C_z",
        "outputId": "a3fdcd9e-8055-4e8c-c221-ae43098ed536"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "env = wrap_env(gym.make(env_name), record_every=1000)\n",
        "\n",
        "agent_args = {\n",
        "            'input_shape': (4, frame_crops[model], frame_crops[model]),\n",
        "            'action_size': env.action_space.n,\n",
        "            'device': device,\n",
        "            'buffer_size': 100000,\n",
        "            'batch_size': 64,\n",
        "            'gamma': 0.99,\n",
        "            'lr': 1e-4,\n",
        "            'tau': 1e-3,\n",
        "            'learn_every': train_every,\n",
        "            'replay_after': 10000,\n",
        "            'memory_tophalf': True,\n",
        "            'episodes': Number_of_episodes\n",
        "        }\n",
        "\n",
        "if model == 'DQNcnn':\n",
        "    agent_args = {**agent_args, 'model': DQNCnn, 'base_filename': 'atari_atlantas_models1'}\n",
        "elif model == 'ResNetDQN':\n",
        "    agent_args = {**agent_args, 'model': ResNetDQN, 'base_filename': 'atari_atlantas_resnet'}\n",
        "else:\n",
        "    raise Exception('model not found')\n",
        "\n",
        "epsilon_decrease = epsilon_decrease_func(start=0.3, end=0.02, decay=Number_of_episodes/4)\n",
        "# epsilon_decrease = lambda x: 0.05\n",
        "plot_epsilon_func(epsilon_decrease, Number_of_episodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3DpdbkZndf3"
      },
      "source": [
        "#### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "2XfmuL5rndf4",
        "outputId": "8b896933-73de-4b12-dd79-4485999216bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 8000 episodes, train every 20 episodes = 400 train epoch\n",
            "Episode 29\tScore: 13000.0\tAverage Score: 8330.0\t eps:0.3\t  "
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/mikesemple/Google Drive/uni/341 - Robot Perception/group4/assignment2.ipynb Cell 33'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000032?line=0'>1</a>\u001b[0m agent \u001b[39m=\u001b[39m DQNAgent(agent_args)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000032?line=1'>2</a>\u001b[0m agent\u001b[39m.\u001b[39mload()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000032?line=2'>3</a>\u001b[0m scores \u001b[39m=\u001b[39m trainDQN(agent, epsilon_decrease, n_episodes\u001b[39m=\u001b[39;49mNumber_of_episodes, save_every\u001b[39m=\u001b[39;49msave_models_every, plot_every\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, network\u001b[39m=\u001b[39;49mmodel)\n",
            "\u001b[1;32m/Users/mikesemple/Google Drive/uni/341 - Robot Perception/group4/assignment2.ipynb Cell 27'\u001b[0m in \u001b[0;36mtrainDQN\u001b[0;34m(agent, epsilon_decrease, n_episodes, network, start_epoch, save_every, plot_every, log_eps)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000026?line=15'>16</a>\u001b[0m     score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000026?line=16'>17</a>\u001b[0m     next_state \u001b[39m=\u001b[39m stack_frames(state, next_state, is_new\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000026?line=17'>18</a>\u001b[0m     agent\u001b[39m.\u001b[39;49mstep(state, action, reward, next_state, done)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000026?line=18'>19</a>\u001b[0m     state \u001b[39m=\u001b[39m next_state\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000026?line=19'>20</a>\u001b[0m scores\u001b[39m.\u001b[39mappend(score)\n",
            "\u001b[1;32m/Users/mikesemple/Google Drive/uni/341 - Robot Perception/group4/assignment2.ipynb Cell 24'\u001b[0m in \u001b[0;36mDQNAgent.step\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000023?line=61'>62</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory) \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplay_after:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000023?line=62'>63</a>\u001b[0m     experiences \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39msample()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000023?line=63'>64</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearn(experiences)\n",
            "\u001b[1;32m/Users/mikesemple/Google Drive/uni/341 - Robot Perception/group4/assignment2.ipynb Cell 24'\u001b[0m in \u001b[0;36mDQNAgent.learn\u001b[0;34m(self, experiences)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000023?line=95'>96</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000023?line=96'>97</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000023?line=97'>98</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msoft_update(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy_net, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_net, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtau)\n",
            "\u001b[1;32m/Users/mikesemple/Google Drive/uni/341 - Robot Perception/group4/assignment2.ipynb Cell 24'\u001b[0m in \u001b[0;36mDQNAgent.soft_update\u001b[0;34m(self, policy_model, target_model, tau)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000023?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msoft_update\u001b[39m(\u001b[39mself\u001b[39m, policy_model, target_model, tau):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000023?line=102'>103</a>\u001b[0m     \u001b[39mfor\u001b[39;00m target_param, policy_param \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(target_model\u001b[39m.\u001b[39mparameters(), policy_model\u001b[39m.\u001b[39mparameters()):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/mikesemple/Google%20Drive/uni/341%20-%20Robot%20Perception/group4/assignment2.ipynb#ch0000023?line=103'>104</a>\u001b[0m         target_param\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mcopy_(tau\u001b[39m*\u001b[39;49mpolicy_param\u001b[39m.\u001b[39;49mdata \u001b[39m+\u001b[39;49m (\u001b[39m1.0\u001b[39;49m\u001b[39m-\u001b[39;49mtau)\u001b[39m*\u001b[39;49mtarget_param\u001b[39m.\u001b[39;49mdata)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "agent = DQNAgent(agent_args)\n",
        "agent.load()\n",
        "scores = trainDQN(agent, epsilon_decrease, n_episodes=Number_of_episodes, save_every=save_models_every, plot_every=1000, network=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDIRbuQUndf8"
      },
      "outputs": [],
      "source": [
        "_ = plt.hist(scores, bins=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzRetiqKndf-"
      },
      "outputs": [],
      "source": [
        "show_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE-yFm4M4DoR"
      },
      "outputs": [],
      "source": [
        "def finalPlay(agent):\n",
        "    env = wrap_env(gym.make(env_name))\n",
        "    score = 0\n",
        "    state = stack_frames(None, env.reset(), True)\n",
        "    while True:\n",
        "        # env.render()\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        score += reward\n",
        "        state = stack_frames(state, next_state)\n",
        "        if done:\n",
        "            print(\"You Final score is:\", score)\n",
        "            break \n",
        "    env.close()\n",
        "finalPlay(agent)\n",
        "show_video()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyBB-sqS3F0i"
      },
      "source": [
        "### DQN2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeDcleB_WV2W"
      },
      "outputs": [],
      "source": [
        "class DQN2(nn.Module):\n",
        "    def __init__(self, h, w, outputs):\n",
        "        super(DQN2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Number of Linear input connections depends on output of conv2d layers\n",
        "        # and therefore the input image size, so compute it.\n",
        "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
        "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
        "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
        "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
        "        linear_input_size = convw * convh * 32\n",
        "        self.head = nn.Linear(linear_input_size, outputs)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        print(\"in size\", x.size())\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        print(\"2 size\", x.size())\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        print(\"3 size\", x.size())\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        return self.head(x.view(x.size(0), -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_bgOQObndgD"
      },
      "outputs": [],
      "source": [
        "def get_output_size(in_size, kernel_size, stride=1, padding=0):\n",
        "    integer = int((in_size - kernel_size + 2 * padding) / stride) == ((in_size - kernel_size + 2 * padding) / stride)\n",
        "    if not integer:\n",
        "        print(\"not int\", ((in_size - kernel_size + 2 * padding) / stride))\n",
        "    return int((in_size - kernel_size + 2 * padding) / stride) + 1\n",
        "\n",
        "get_output_size(in_size=84, kernel_size=3, stride=2, padding=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqqu-qq39Swm"
      },
      "outputs": [],
      "source": [
        "class DQNtst(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "        #in = 299x299\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=0), #out = 149x149\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            # nn.Dropout(0.3),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0), #out = 147x147\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), #out = 147x147\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0) #out = 73x73                    \n",
        "        )\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "                  nn.Linear(state_space_dim,64),\n",
        "                  nn.ReLU(),\n",
        "                  nn.Linear(64,64*2),\n",
        "                  nn.ReLU(),\n",
        "                  nn.Linear(64*2,action_space_dim)\n",
        "                )\n",
        "# (33600x3 and 210x64)\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        print('in size=', x.size())\n",
        "        x = self.block1(x)\n",
        "        print('block1 size=', x.size())\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRwZZtBSS4ti"
      },
      "outputs": [],
      "source": [
        "class DQNCnn(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "        \n",
        "        self.features = nn.Sequential( # in = 84x84\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU()\n",
        "        ) # out = 7x7\n",
        "        self.feature_size = 7 * 7 * 64\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.feature_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.num_actions)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bfd5JgWoICcg",
        "zyBEYPP0H-qS",
        "yeaT5VbKKpSE"
      ],
      "include_colab_link": true,
      "name": "working.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "967264ae980203440ddaee0507bc3cd46af5e06b6d5472ede725bb9edfce0d78"
    },
    "kernelspec": {
      "display_name": "Python (env)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
